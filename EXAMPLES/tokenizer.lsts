
import LIB/default.lm;
import SRC/index-definitions.lm;

let lsts-tokenize(text: String): List<String> = (
   let tokens = [] :: List<String>;
   while non-zero(text) {match text {
      (m=/^de/)..rest => (print("D.."); print(m); text = "";);
      "a"..rest => (print("A.."); print(rest); text="";);
      "abc" => (print("ABC"); text = "";);
      rst => (print("Default: "); print(rst); text = "";);
   #   "\s"..rst => text = rst;
   #   "\t"..rst => text = rst;
   #   "\n"..rst => text = rst;
   #   rst => fail("Unexpected Character In LSTS Tokenization: '\{rst[0]}'");
   }};
   tokens
);

print(lsts-tokenize(intern(read-file(untern("EXAMPLES/tokenizer.lsts")))));
