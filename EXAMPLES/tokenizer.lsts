
import LIB/default.lm;
import SRC/index-definitions.lm;

let lsts-tokenize(text: String): List<String> = (
   let tokens = [] :: List<String>;
   while non-zero(text) {match text {
      "\s".. rest => text = rest;
      "\t".. rest => text = rest;
      "\n".. rest => text = rest;

      "\\".. rest => (tokens = cons(text[:"\\".length], tokens); text = rest;);
      "~=".. rest => (tokens = cons(text[:"~=".length], tokens); text = rest;);
      "+=".. rest => (tokens = cons(text[:"+=".length], tokens); text = rest;);
      "-=".. rest => (tokens = cons(text[:"-=".length], tokens); text = rest;);
      "*=".. rest => (tokens = cons(text[:"*=".length], tokens); text = rest;);
      "/=".. rest => (tokens = cons(text[:"/=".length], tokens); text = rest;);
      "%=".. rest => (tokens = cons(text[:"%=".length], tokens); text = rest;);
      "&=".. rest => (tokens = cons(text[:"&=".length], tokens); text = rest;);
      "|=".. rest => (tokens = cons(text[:"|=".length], tokens); text = rest;);
      "<=".. rest => (tokens = cons(text[:"<=".length], tokens); text = rest;);
      ">=".. rest => (tokens = cons(text[:">=".length], tokens); text = rest;);
      "==".. rest => (tokens = cons(text[:"==".length], tokens); text = rest;);
      "!=".. rest => (tokens = cons(text[:"!=".length], tokens); text = rest;);
      "&&".. rest => (tokens = cons(text[:"!=".length], tokens); text = rest;);
      "||".. rest => (tokens = cons(text[:"!=".length], tokens); text = rest;);
      "<".. rest => (tokens = cons(text[:"<".length], tokens); text = rest;);
      ">".. rest => (tokens = cons(text[:">".length], tokens); text = rest;);
      "{".. rest => (tokens = cons(text[:"{".length], tokens); text = rest;);
      "}".. rest => (tokens = cons(text[:"}".length], tokens); text = rest;);
      "[".. rest => (tokens = cons(text[:"[".length], tokens); text = rest;);
      "]".. rest => (tokens = cons(text[:"]".length], tokens); text = rest;);
      "(".. rest => (tokens = cons(text[:"(".length], tokens); text = rest;);
      ")".. rest => (tokens = cons(text[:")".length], tokens); text = rest;);
      ":".. rest => (tokens = cons(text[:":".length], tokens); text = rest;);
      ";".. rest => (tokens = cons(text[:";".length], tokens); text = rest;);
      ",".. rest => (tokens = cons(text[:",".length], tokens); text = rest;);
      "?".. rest => (tokens = cons(text[:"?".length], tokens); text = rest;);
      "~".. rest => (tokens = cons(text[:"~".length], tokens); text = rest;);
      "@".. rest => (tokens = cons(text[:"@".length], tokens); text = rest;);
      "+".. rest => (tokens = cons(text[:"+".length], tokens); text = rest;);
      "-".. rest => (tokens = cons(text[:"-".length], tokens); text = rest;);
      "*".. rest => (tokens = cons(text[:"*".length], tokens); text = rest;);
      "/".. rest => (tokens = cons(text[:"/".length], tokens); text = rest;);
      "%".. rest => (tokens = cons(text[:"%".length], tokens); text = rest;);
      "&".. rest => (tokens = cons(text[:"&".length], tokens); text = rest;);
      "|".. rest => (tokens = cons(text[:"|".length], tokens); text = rest;);
      "!".. rest => (tokens = cons(text[:"!".length], tokens); text = rest;);
      "=".. rest => (tokens = cons(text[:"=".length], tokens); text = rest;);
      "^".. rest => (tokens = cons(text[:"^".length], tokens); text = rest;);
      ".".. rest => (tokens = cons(text[:".".length], tokens); text = rest;);

      (lit=r/^["]([^"\\]|([\\].))*["]/).. rest => (
         tokens = cons(text[:lit.length], tokens); text = rest;
      );

      (rgx=r/^r[\/]([^\/]|([\\].))*[\/]/).. rest => (
         tokens = cons(text[:rgx.length], tokens); text = rest;
      );

      (id=r/^[a-zA-Z0-9_]+/).. rest => (
         tokens = cons(text[:id.length], tokens); text = rest;
      );

      (comment=r/^#[^\n]*[\n]/).. rest => (
         text = rest;
      );

      #rest => fail("Unexpected Character during LSTS Tokenization: "
      #             "'\{rest[0]}' "
      #             "in File \{rest.file-name-of-token}, "
      #             "Line \{rest.line-of-token}, "
      #             "Column \{rest.column-of-token}.");
      rest => ( fail("Unrecognized Token: \{rest}"); );
   }; };
   tokens.reverse
);

print(lsts-tokenize(intern(read-file(untern("EXAMPLES/tokenizer.lsts")))));
